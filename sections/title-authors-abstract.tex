% Title
\title{Adapting Surprise Minimizing Reinforcement Learning Techniques for Transactive Control}
% Authors
% \author{William Arnold\tsc{*1}, Tarang Srivastava \tsc{*1}, Lucas Spangher \tsc{1}, Utkarsha Agwan\tsc{1}, Costas Spanos \tsc{1}}

\affiliation{
    % \institution{* Both authors contributed equally to this research.}
    \institution{1. Department of Electrical Engineering and Computer Sciences, University of California, Berkeley}
    \country{}
}

\begin{abstract}
Optimizing prices for energy demand response requires a flexible controller with ability to navigate complex environments. 
We propose a reinforcement learning controller with surprise minimizing modifications in its architecture. 
We suggest that surprise minimization can be used to improve learning speed, taking advantage of predictability in peoples' energy usage. Our architecture performs well in a simulation of energy demand response. We propose this modification to improve functionality and savin a large-scale experiment.   
\end{abstract}

% \keywords{reinforcement learning, demand response,  transactive energy, 
% surprise minimization, SMiRL}

\begin{CCSXML}
<ccs2012>
   <concept>
       <concept_id>10010147.10010257.10010258.10010261</concept_id>
       <concept_desc>Computing methodologies~Reinforcement learning</concept_desc>
       <concept_significance>500</concept_significance>
       </concept>
   <concept>
       <concept_id>10010583.10010662.10010668.10010672</concept_id>
       <concept_desc>Hardware~Smart grid</concept_desc>
       <concept_significance>500</concept_significance>
       </concept>
 </ccs2012>
\end{CCSXML}

\ccsdesc[500]{Computing methodologies~Reinforcement learning}
\ccsdesc[500]{Hardware~Smart grid}
